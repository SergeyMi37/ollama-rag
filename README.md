# ollama-RAG   üçÅ
# –°–ø–∞—Å–∏–±–æ –∞–≤—Ç–æ—Ä—É https://habr.com/ru/articles/931396/
# –ü—Ä–∏–º–µ—Ä 1. RAG —Å LangChain (–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ FAISS + OpenAI):
# –í —ç—Ç–æ–º –∫–æ–¥–µ –º—ã: –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏, —Ä–µ–∂–µ–º –∏—Ö –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ ~1000 —Å–∏–º–≤–æ–ª–æ–≤, –ø–æ–ª—É—á–∞–µ–º –¥–ª—è –Ω–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ OpenAI, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å FAISS, –∑–∞—Ç–µ–º –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ø-3 –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∏ –ø–µ—Ä–µ–¥–∞–µ–º –∏—Ö –≤–º–µ—Å—Ç–µ —Å –≤–æ–ø—Ä–æ—Å–æ–º –≤ –º–æ–¥–µ–ª—å GPT-3.5. –¶–µ–ø–æ—á–∫–∞ RetrievalQA (—Ç–∏–ø stuff) –ø—Ä–æ—Å—Ç–æ ¬´–ø–æ–¥–∫–ª–∞–¥—ã–≤–∞–µ—Ç¬ª –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –≤ –ø—Ä–æ–º–ø—Ç. –†–µ–∑—É–ª—å—Ç–∞—Ç (result) ‚Äì —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç. –í —Ä–µ–∞–ª—å–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏, –≤–º–µ—Å—Ç–æ –ø–µ—á–∞—Ç–∏, –º–æ–∂–Ω–æ –æ–±–µ—Ä–Ω—É—Ç—å —ç—Ç–æ –≤ –≤–µ–±-—Å–µ—Ä–≤–∏—Å –∏–ª–∏ —á–∞—Ç-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.
# –ü—Ä–∏–º–µ—Ä 2. RAG —Å LlamaIndex:

``` bash
git clone https://github.com/SergeyMi37/ollama-rag
cd ollama-rag
```

Create virtual environment (optional)
``` bash
python3 -m venv env
source env/bin/activate
```

Create virtual environment for Windows
``` bash
python -m venv env
source env/Scripts/activate
```

Install all requirements:
``` bash
pip install -r requirements.txt
```

–£–∫–∞–∂–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω—É—é –∏ —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
``` bash
python llama-core.py # embedding_model="nomic-embed-text"   llm_model="llama2"
python llama-rag.py "mxbai-embed-large" "llama3.1" # –°–æ–≥–ª–∞—Å–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º, –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –Ω–æ–º–µ—Ä —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–∞–Ω–Ω–æ–π —Ñ—Ä–∞–∑–µ, ‚Äî —ç—Ç–æ 2.2.
python llama-rag.py "mxbai-embed-large" "infidelis/GigaChat-20B-A3B-instruct-v1.5:q5_0" # –¢–µ–∫—Å—Ç "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤–æ–¥–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ" —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–º–µ —Å –Ω–æ–º–µ—Ä–æ–º **2.2**.
```

